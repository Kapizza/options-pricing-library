{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Calibration Benchmark (rBergomi / Rough Heston)\n",
    "\n",
    "This notebook benchmarks different parallel backends, worker counts, and batch sizes for the local machine,\n",
    "to recommend mc['batch_size'] and n_workers for calibration.\n",
    "\n",
    "- Backends: threads vs processes\n",
    "- Workers: a few sensible counts around CPU cores\n",
    "- Batch sizes: tuned per model (rBergomi vs Rough Heston)\n",
    "\n",
    "Uses the optimized terminal-only simulators to mimic calibration workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, math, time, statistics as stats\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "import os, sys, math, json, time, hashlib\n",
    "import numpy as np\n",
    "from matplotlib import cm, colors, rcParams\n",
    "rcParams['font.family'] = 'Times New Roman'\n",
    "import matplotlib.pyplot as plt\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.append(repo_root)\n",
    "\n",
    "from src.rough import (\n",
    "    rbergomi_terminal_parallel_pool,\n",
    "    rough_heston_terminal_parallel_pool,\n",
    ")\n",
    "\n",
    "# keep BLAS threads to 1 to avoid oversubscription\n",
    "for var in (\"OMP_NUM_THREADS\", \"MKL_NUM_THREADS\", \"OPENBLAS_NUM_THREADS\", \"NUMEXPR_NUM_THREADS\"):\n",
    "    os.environ.setdefault(var, \"1\")\n",
    "\n",
    "cores = os.cpu_count() or 4\n",
    "cores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_rbergomi(n_paths=20000, N=128, reps=1):\n",
    "    S0, r, q = 100.0, 0.01, 0.0\n",
    "    T, H, eta, rho, xi0 = 0.5, 0.12, 1.5, -0.6, 0.04\n",
    "    backends = ['thread', 'process']\n",
    "    worker_cands = sorted(set([min(4, cores), min(8, cores), max(1, cores//2), cores]))\n",
    "    bs_cands = [2048, 4096, 8192] + ([16384] if n_paths >= 16384 else [])\n",
    "    results = []\n",
    "    for backend in backends:\n",
    "        Exec = ThreadPoolExecutor if backend=='thread' else ProcessPoolExecutor\n",
    "        for nw in worker_cands:\n",
    "            for bs in bs_cands:\n",
    "                t0 = time.perf_counter()\n",
    "                for _ in range(reps):\n",
    "                    with Exec(max_workers=int(nw)) as ex:\n",
    "                        ST = rbergomi_terminal_parallel_pool(\n",
    "                            ex, S0=S0, T=T, N=N, n_paths=n_paths, H=H, eta=eta, rho=rho, xi0=xi0,\n",
    "                            r=r, q=q, base_seed=12345, fgn_method='davies-harte', batch_size=bs\n",
    "                        )\n",
    "                dt = time.perf_counter()-t0\n",
    "                results.append((dt/reps, backend, int(nw), int(bs)))\n",
    "    results.sort()\n",
    "    return results\n",
    "\n",
    "def bench_rough(n_paths=10000, N=96, reps=1):\n",
    "    S0, r, q = 100.0, 0.01, 0.0\n",
    "    T, v0, kappa, theta, eta, rho, H = 0.6, 0.04, 1.6, 0.04, 1.8, -0.7, 0.10\n",
    "    backends = ['thread', 'process']\n",
    "    worker_cands = sorted(set([min(4, cores), min(8, cores), max(1, cores//2), cores]))\n",
    "    bs_cands = [512, 1024, 2048, 4096]\n",
    "    results = []\n",
    "    for backend in backends:\n",
    "        Exec = ThreadPoolExecutor if backend=='thread' else ProcessPoolExecutor\n",
    "        for nw in worker_cands:\n",
    "            for bs in bs_cands:\n",
    "                t0 = time.perf_counter()\n",
    "                for _ in range(reps):\n",
    "                    with Exec(max_workers=int(nw)) as ex:\n",
    "                        ST = rough_heston_terminal_parallel_pool(\n",
    "                            ex, S0=S0, v0=v0, T=T, N=N, n_paths=n_paths, H=H, kappa=kappa, theta=theta, eta=eta, rho=rho,\n",
    "                            r=r, q=q, base_seed=23456, batch_size=bs\n",
    "                        )\n",
    "                dt = time.perf_counter()-t0\n",
    "                results.append((dt/reps, backend, int(nw), int(bs)))\n",
    "    results.sort()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.1881846000032965, 'thread', 6, 4096),\n",
       "  (0.1971789999952307, 'thread', 12, 4096),\n",
       "  (0.21670309999899473, 'thread', 8, 4096),\n",
       "  (0.25177979999716626, 'thread', 6, 8192),\n",
       "  (0.2544190999979037, 'thread', 4, 4096)],\n",
       " [(0.03448140000546118, 'thread', 8, 2048),\n",
       "  (0.034725000004982576, 'thread', 4, 4096),\n",
       "  (0.03523489999497542, 'thread', 4, 2048),\n",
       "  (0.0353051999991294, 'thread', 8, 512),\n",
       "  (0.03655150000122376, 'thread', 4, 1024)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run short sweeps (adjust n_paths/N up for more stable results)\n",
    "rbergomi_results = bench_rbergomi(n_paths=20000, N=128, reps=1)\n",
    "rough_results    = bench_rough(n_paths=10000,  N=96,  reps=1)\n",
    "rbergomi_results[:5], rough_results[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rBergomi best: time=0.188s, backend=thread, n_workers=6, batch_size=4096\n",
      "Top 5:\n",
      "  0.188s  backend=thread  n_workers= 6  batch= 4096\n",
      "  0.197s  backend=thread  n_workers=12  batch= 4096\n",
      "  0.217s  backend=thread  n_workers= 8  batch= 4096\n",
      "  0.252s  backend=thread  n_workers= 6  batch= 8192\n",
      "  0.254s  backend=thread  n_workers= 4  batch= 4096\n",
      "RoughHeston best: time=0.034s, backend=thread, n_workers=8, batch_size=2048\n",
      "Top 5:\n",
      "  0.034s  backend=thread  n_workers= 8  batch= 2048\n",
      "  0.035s  backend=thread  n_workers= 4  batch= 4096\n",
      "  0.035s  backend=thread  n_workers= 4  batch= 2048\n",
      "  0.035s  backend=thread  n_workers= 8  batch=  512\n",
      "  0.037s  backend=thread  n_workers= 4  batch= 1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'backend': 'thread', 'n_workers': 6, 'batch_size': 4096},\n",
       " {'backend': 'thread', 'n_workers': 8, 'batch_size': 2048, 'use_numba': True})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize(name, results):\n",
    "    best = results[0]\n",
    "    print(f'{name} best: time={best[0]:.3f}s, backend={best[1]}, n_workers={best[2]}, batch_size={best[3]}')\n",
    "    print('Top 5:')\n",
    "    for row in results[:5]:\n",
    "        print(f'  {row[0]:.3f}s  backend={row[1]:6s}  n_workers={row[2]:2d}  batch={row[3]:5d}')\n",
    "    return dict(backend=best[1], n_workers=int(best[2]), batch_size=int(best[3]))\n",
    "\n",
    "cfg_rbergomi = summarize('rBergomi', rbergomi_results)\n",
    "cfg_rough    = summarize('RoughHeston', rough_results)\n",
    "cfg_rough[\"use_numba\"] = True\n",
    "cfg_rbergomi, cfg_rough\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested usage\n",
    "Use the best settings in your mc dict and pass the backend to calibration:\n",
    "\n",
    "```python\n",
    "best_rb = cfg_rbergomi\n",
    "out_rb, _ = calibrate_rbergomi(\n",
    "    smiles,\n",
    "    mc=dict(N=192, paths=12000, fgn_method='davies-harte',\n",
    "            batch_size=best_rb['batch_size'], n_workers=best_rb['n_workers']),\n",
    "    parallel_backend=best_rb['backend'],\n",
    "    terminal_only=True,\n",
    ")\n",
    "\n",
    "best_rh = cfg_rough\n",
    "out_rh, _ = calibrate_rough_heston(\n",
    "    smiles,\n",
    "    mc=dict(N=192, paths=12000,\n",
    "            batch_size=best_rh['batch_size'], n_workers=best_rh['n_workers']),\n",
    "    parallel_backend=best_rh['backend'],\n",
    "    terminal_only=True,\n",
    ")\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
